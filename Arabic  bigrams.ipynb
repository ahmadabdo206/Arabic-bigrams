{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('Text Document.txt', 'r', encoding='utf-8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'القائمة الرئيسية',\n",
       " '',\n",
       " 'ويكيبيديا',\n",
       " 'ابحث في ويكيبيديا',\n",
       " 'بحث',\n",
       " 'إنشاء حساب',\n",
       " 'دخول',\n",
       " '',\n",
       " 'أدوات شخصية',\n",
       " '\\t',\n",
       " 'تضامنا مع حق الشعب الفلسطيني',\n",
       " 'لا للإبادة الجماعية في غزة .... لا لقتل المدنيين',\n",
       " 'لا لاستهداف المستشفيات والمدارس .... لا للتضليل والكيل بمكيالين',\n",
       " 'أوقفوا الحرب .... وانشروا السلام العادل والشامل',\n",
       " '',\n",
       " 'الصفحة الرئيسة',\n",
       " 'نقاش',\n",
       " 'اقرأ',\n",
       " 'عرض المصدر']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '%',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '«',\n",
       " '®',\n",
       " '²',\n",
       " '·',\n",
       " '»',\n",
       " 'é',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'έ',\n",
       " 'α',\n",
       " 'γ',\n",
       " 'ε',\n",
       " 'ι',\n",
       " 'κ',\n",
       " 'λ',\n",
       " 'ν',\n",
       " 'ο',\n",
       " 'π',\n",
       " 'ς',\n",
       " 'σ',\n",
       " 'τ',\n",
       " 'υ',\n",
       " 'ό',\n",
       " 'В',\n",
       " 'Р',\n",
       " 'С',\n",
       " 'и',\n",
       " 'о',\n",
       " 'с',\n",
       " 'ֵ',\n",
       " 'ַ',\n",
       " 'ּ',\n",
       " 'ׁ',\n",
       " 'א',\n",
       " 'ה',\n",
       " 'ו',\n",
       " 'י',\n",
       " 'ע',\n",
       " 'ש',\n",
       " '،',\n",
       " '؛',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'إ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ى',\n",
       " 'ي',\n",
       " '٠',\n",
       " '١',\n",
       " '٬',\n",
       " 'ٱ',\n",
       " 'پ',\n",
       " 'ڤ',\n",
       " 'ی',\n",
       " 'ܘ',\n",
       " 'ܝ',\n",
       " 'ܥ',\n",
       " 'ܫ',\n",
       " 'ݠ',\n",
       " 'ग',\n",
       " 'त',\n",
       " 'थ',\n",
       " 'द',\n",
       " 'ध',\n",
       " 'म',\n",
       " 'र',\n",
       " 'स',\n",
       " 'ा',\n",
       " 'ि',\n",
       " 'ौ',\n",
       " '्',\n",
       " 'ὁ',\n",
       " 'ὐ',\n",
       " '\\u200c',\n",
       " '\\u200f',\n",
       " '–',\n",
       " '—',\n",
       " '“',\n",
       " '”',\n",
       " '•',\n",
       " '→',\n",
       " '↓',\n",
       " '⇧',\n",
       " '✎',\n",
       " '👈']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = []\n",
    "with open('New Text Document (2).txt', 'r', encoding='utf-8') as sentences:\n",
    "  for line in sentences:\n",
    "    for char in line:\n",
    "      characters.append(char)\n",
    "characters=sorted(list(set(characters)))\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ar_characters=['ء','آ','أ','ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش'\n",
    "               , 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ٱ']\n",
    "len(Ar_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6055,\n",
       " ['القائمة',\n",
       "  'ابحث',\n",
       "  'في',\n",
       "  'بحث',\n",
       "  'إنشاء',\n",
       "  'حساب',\n",
       "  'دخول',\n",
       "  'أدوات',\n",
       "  'شخصية',\n",
       "  'تضامنا',\n",
       "  'مع',\n",
       "  'حق',\n",
       "  'الشعب',\n",
       "  'لا',\n",
       "  'للإبادة',\n",
       "  'غزة',\n",
       "  'لقتل',\n",
       "  'للتضليل',\n",
       "  'والكيل',\n",
       "  'أوقفوا'],\n",
       " ['الكونغو',\n",
       "  'تومي',\n",
       "  'شعوب',\n",
       "  'أنتيغوا',\n",
       "  'كيتس',\n",
       "  'فنسنت',\n",
       "  'وتوباغو',\n",
       "  'بوينس',\n",
       "  'آيرس',\n",
       "  'آشوريون',\n",
       "  'سريان',\n",
       "  'كلدان',\n",
       "  'بلدان',\n",
       "  'وأقاليم',\n",
       "  'جزر',\n",
       "  'مسارد',\n",
       "  'وتراجم',\n",
       "  'أبجدي',\n",
       "  'رئيسية'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_words(Old_File, New_File):\n",
    "    with open(Old_File, 'r', encoding='utf-8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    filtered_sentences = []\n",
    "    for line in sentences:\n",
    "        \n",
    "        words = line.split()\n",
    "        \n",
    "        filtered_words = [word for word in words if all(char in Ar_characters for char in word)]\n",
    "        filtered_sentences.append(filtered_words)\n",
    "    all_words = []    \n",
    "    for  line in filtered_sentences:\n",
    "        for words in line:\n",
    "            if len(words)<=7:\n",
    "                if words not in all_words:\n",
    "                    all_words.append(words)\n",
    "                    \n",
    "    for word in all_words:\n",
    "        with open(New_File, 'a', encoding='utf-8') as out_file:\n",
    "            out_file.write(word + '\\n')\n",
    "      \n",
    "    return(all_words)\n",
    "    \n",
    "\n",
    "            \n",
    "new_words = filter_words('Text Document.txt','F:\\\\Arabic_names.txt')\n",
    "len(new_words),new_words[:20],new_words[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('F:\\\\IE\\\\Andrej Karpathy\\\\1\\\\Ar_names.txt', 'r', encoding='utf-8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['القائمة',\n",
       " 'ابحث',\n",
       " 'في',\n",
       " 'بحث',\n",
       " 'إنشاء',\n",
       " 'حساب',\n",
       " 'دخول',\n",
       " 'أدوات',\n",
       " 'شخصية',\n",
       " 'تضامنا',\n",
       " 'مع',\n",
       " 'حق',\n",
       " 'الشعب',\n",
       " 'لا',\n",
       " 'للإبادة',\n",
       " 'غزة',\n",
       " 'لقتل',\n",
       " 'للتضليل',\n",
       " 'والكيل',\n",
       " 'أوقفوا']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ء': 1,\n",
       " 'آ': 2,\n",
       " 'أ': 3,\n",
       " 'ؤ': 4,\n",
       " 'إ': 5,\n",
       " 'ئ': 6,\n",
       " 'ا': 7,\n",
       " 'ب': 8,\n",
       " 'ة': 9,\n",
       " 'ت': 10,\n",
       " 'ث': 11,\n",
       " 'ج': 12,\n",
       " 'ح': 13,\n",
       " 'خ': 14,\n",
       " 'د': 15,\n",
       " 'ذ': 16,\n",
       " 'ر': 17,\n",
       " 'ز': 18,\n",
       " 'س': 19,\n",
       " 'ش': 20,\n",
       " 'ص': 21,\n",
       " 'ض': 22,\n",
       " 'ط': 23,\n",
       " 'ظ': 24,\n",
       " 'ع': 25,\n",
       " 'غ': 26,\n",
       " 'ف': 27,\n",
       " 'ق': 28,\n",
       " 'ك': 29,\n",
       " 'ل': 30,\n",
       " 'م': 31,\n",
       " 'ن': 32,\n",
       " 'ه': 33,\n",
       " 'و': 34,\n",
       " 'ى': 35,\n",
       " 'ي': 36,\n",
       " 'ٱ': 37,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'ء',\n",
       " 2: 'آ',\n",
       " 3: 'أ',\n",
       " 4: 'ؤ',\n",
       " 5: 'إ',\n",
       " 6: 'ئ',\n",
       " 7: 'ا',\n",
       " 8: 'ب',\n",
       " 9: 'ة',\n",
       " 10: 'ت',\n",
       " 11: 'ث',\n",
       " 12: 'ج',\n",
       " 13: 'ح',\n",
       " 14: 'خ',\n",
       " 15: 'د',\n",
       " 16: 'ذ',\n",
       " 17: 'ر',\n",
       " 18: 'ز',\n",
       " 19: 'س',\n",
       " 20: 'ش',\n",
       " 21: 'ص',\n",
       " 22: 'ض',\n",
       " 23: 'ط',\n",
       " 24: 'ظ',\n",
       " 25: 'ع',\n",
       " 26: 'غ',\n",
       " 27: 'ف',\n",
       " 28: 'ق',\n",
       " 29: 'ك',\n",
       " 30: 'ل',\n",
       " 31: 'م',\n",
       " 32: 'ن',\n",
       " 33: 'ه',\n",
       " 34: 'و',\n",
       " 35: 'ى',\n",
       " 36: 'ي',\n",
       " 37: 'ٱ',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 38)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi), len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((38, 38), dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chr in words:\n",
    "  chs = ['.'] + list(chr) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    N[ix1, ix2] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     0,   884,  8632,     0,  2886,     0, 55780, 14411,     5,\n",
       "        15938,  1452,  4756,  6066,  2212,  3428,   769,  4381,  1192,  5915,\n",
       "         3308,  2571,   437,  2175,   306,  8084,  1619,  7920,  4425,  5943,\n",
       "        11345, 24361,  5061,  3309, 23152,     5,  6613,   130],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0036),\n",
       " tensor(0.0036),\n",
       " tensor(0.0068),\n",
       " tensor(0.0347),\n",
       " tensor(0.0036),\n",
       " tensor(0.0140),\n",
       " tensor(0.0036),\n",
       " tensor(0.2048),\n",
       " tensor(0.0556),\n",
       " tensor(0.0036),\n",
       " tensor(0.0611),\n",
       " tensor(0.0088),\n",
       " tensor(0.0207),\n",
       " tensor(0.0255),\n",
       " tensor(0.0116),\n",
       " tensor(0.0160),\n",
       " tensor(0.0064),\n",
       " tensor(0.0194),\n",
       " tensor(0.0079),\n",
       " tensor(0.0249),\n",
       " tensor(0.0155),\n",
       " tensor(0.0129),\n",
       " tensor(0.0052),\n",
       " tensor(0.0114),\n",
       " tensor(0.0047),\n",
       " tensor(0.0327),\n",
       " tensor(0.0094),\n",
       " tensor(0.0322),\n",
       " tensor(0.0195),\n",
       " tensor(0.0250),\n",
       " tensor(0.0445),\n",
       " tensor(0.0914),\n",
       " tensor(0.0218),\n",
       " tensor(0.0155),\n",
       " tensor(0.0871),\n",
       " tensor(0.0036),\n",
       " tensor(0.0274),\n",
       " tensor(0.0041)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = (N+995).float()\n",
    "P /= P.sum(1, keepdims=True)\n",
    "list(P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999403953552"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[1].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نقطة.\n",
      "م.\n",
      "تالأرة.\n",
      "تص.\n",
      "مالعند.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = N[ix].float()\n",
    "    p = p / p.sum()\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  1453893\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((38, 38), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch 4.235983371734619\n",
      "5 epoch 3.282212972640991\n",
      "10 epoch 3.0958139896392822\n",
      "15 epoch 3.0035343170166016\n",
      "20 epoch 2.9488487243652344\n",
      "25 epoch 2.9133543968200684\n",
      "30 epoch 2.888604164123535\n",
      "35 epoch 2.8705005645751953\n",
      "40 epoch 2.856851100921631\n",
      "45 epoch 2.8463404178619385\n",
      "إجمالي وقت التنفيذ: 113.14499235153198 ثانية\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # تسجيل وقت البدء قبل تنفيذ الكود\n",
    "# تنفيذ الكود الذي تريد قياسه\n",
    "epoch= 50\n",
    "\n",
    "# gradient descent\n",
    "for k in range(epoch):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=38).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.1*(W**2).mean()\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad\n",
    "    \n",
    "  if k % (epoch/10) == 0:\n",
    "    print(k,'epoch' ,loss.item())\n",
    "\n",
    "\n",
    "end_time = time.time()  # تسجيل وقت النهاية بعد تنفيذ الكود\n",
    "total_time = end_time - start_time  # حساب إجمالي وقت التنفيذ\n",
    "\n",
    "print(\"إجمالي وقت التنفيذ:\", total_time, \"ثانية\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ن.\n",
      "قة.\n",
      "م.\n",
      "تالأرة.\n",
      "تص.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=38).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
